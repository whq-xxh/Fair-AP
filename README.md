# Fair-AP
Toward Fair and Accurate Cross-Domain Medical Image Segmentation: A VLM-Driven Active Domain Adaptation Paradigm

Thanks for your interest. Code is organizing and will be released.


# How to Run the Code ðŸ› 
### Environment Installation
### 1. Training source models in the source center
For setting up the environment and training the source model, please refer to the [[STDR]](https://github.com/whq-xxh/SFADA-GTV-Seg) project. Please note that some hyperparameters, such as the image input resolution, may need to be adjusted.

### 2. Fair-AP strategy 


### 3. Finetune the source Model with actively enhanced-pseudo labels 
Please refer to the [[STDR]](https://github.com/whq-xxh/SFADA-GTV-Seg) project.



# Citation ðŸ“–

If you find our work useful or relevant to your research, please consider citing:
```
@inproceedings{wang2025toward,
  title={Toward fair and accurate cross-domain medical image segmentation: A vlm-driven active domain adaptation paradigm},
  author={Wang, Hongqiu and Chen, Wu and Luo, Xiangde and Xing, Zhaohu and Liu, Lihao and Qin, Jing and Wu, Shaozhi and Zhu, Lei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={24102--24112},
  year={2025}
}
```

# Comparison with Other Methods ðŸ“ˆ

We acknowledge the developers of the comparative methods in **ADA4MIA** [here](https://github.com/whq-xxh/ADA4MIA).
